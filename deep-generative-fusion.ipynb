{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3935,
     "status": "ok",
     "timestamp": 1648978814851,
     "user": {
      "displayName": "ARSHVEER KAUR",
      "userId": "10582829134183221319"
     },
     "user_tz": -330
    },
    "id": "rH1slEHTjGK7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.nn.functional import normalize\n",
    "# from tensorflow.keras.datasets import mnist\n",
    "# from imutils import build_montages\n",
    "import numpy as np\n",
    "# import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "from osgeo import gdal\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# GPU related info\n",
    "cuda = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and cuda == 1 else \"cpu\") # default gpu\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"data/\"\n",
    "# path_m=\"../../../../Dataset/fusion_modis_landsat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/landsat\n",
      "data/modis\n"
     ]
    }
   ],
   "source": [
    "# landsat_folder=path+\"/landsat_5_1_2014\"\n",
    "landsat_folder=path+\"landsat\"\n",
    "# modis_folder=path+\"/modis_5_1_2014\"\n",
    "modis_folder=path+\"modis\"\n",
    "print(landsat_folder)\n",
    "print(modis_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 46)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_list_ls = os.listdir(landsat_folder)\n",
    "dir_list_md = os.listdir(modis_folder)\n",
    "# type(dir_list)\n",
    "len(dir_list_ls), len(dir_list_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list1):\n",
    " \n",
    "    # initialize a null list\n",
    "    unique_list = []\n",
    " \n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_state(dir_list,sat):\n",
    "    states = []\n",
    "    counties = []\n",
    "    \n",
    "    for i in range(len(dir_list)):\n",
    "        file = dir_list[i]\n",
    "        locations=file[:-4].split(\"_\")\n",
    "#         print('location',locations) \n",
    "        if sat == 'ls':\n",
    "            state = int(locations[1])\n",
    "        if sat == 'md':\n",
    "            state = int(locations[0])\n",
    "        states.append(state)\n",
    "        stat = unique(states)\n",
    "#         print(stat)\n",
    "    return stat\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_county(dir_list, state, sat):\n",
    "    states = []\n",
    "    counties = []\n",
    "    \n",
    "    for i in range(len(dir_list)):\n",
    "        file = dir_list[i]\n",
    "        locations=file[:-4].split(\"_\")\n",
    "#         print('location',locations) \n",
    "        if sat == 'ls':\n",
    "            state_fl = int(locations[1])\n",
    "        if sat == 'md':\n",
    "            state_fl = int(locations[0])\n",
    "\n",
    "        if (state_fl != state):\n",
    "            continue\n",
    "        elif (state_fl == state and sat == 'ls'):\n",
    "            county_fl = int(locations[2])   \n",
    "        elif (state_fl == state and sat == 'md'):\n",
    "            county_fl = int(locations[1])          \n",
    "        counties.append(county_fl)\n",
    "        county = unique(counties)            \n",
    "            \n",
    "            \n",
    "            \n",
    "#         if (state_fl == state and sat == 'ls'):\n",
    "#             county_fl = int(locations[2])\n",
    "#         if (state_fl == state and sat == 'md'):\n",
    "#             county_fl = int(locations[1])            \n",
    "#         counties.append(county_fl)\n",
    "#         county = unique(counties)\n",
    "    return county\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common(a,b): \n",
    "    c = [value for value in a if value in b] \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 23 23\n",
      "23 23 23\n",
      "['5_1_2014_1.tif', '5_1_2014_3.tif', '5_1_2014_5.tif', '5_1_2014_7.tif', '5_1_2014_9.tif', '5_1_2014_11.tif', '5_1_2014_13.tif', '5_1_2014_15.tif', '5_1_2014_17.tif', '5_1_2014_19.tif', '5_1_2014_21.tif', '5_1_2014_23.tif', '5_1_2014_25.tif', '5_1_2014_27.tif', '5_1_2014_29.tif', '5_1_2014_31.tif', '5_1_2014_33.tif', '5_1_2014_35.tif', '5_1_2014_37.tif', '5_1_2014_39.tif', '5_1_2014_41.tif', '5_1_2014_43.tif', '5_1_2014_45.tif']\n",
      "['5_1_2014_1.tif', '5_1_2014_3.tif', '5_1_2014_5.tif', '5_1_2014_7.tif', '5_1_2014_9.tif', '5_1_2014_11.tif', '5_1_2014_13.tif', '5_1_2014_15.tif', '5_1_2014_17.tif', '5_1_2014_19.tif', '5_1_2014_21.tif', '5_1_2014_23.tif', '5_1_2014_25.tif', '5_1_2014_27.tif', '5_1_2014_29.tif', '5_1_2014_31.tif', '5_1_2014_33.tif', '5_1_2014_35.tif', '5_1_2014_37.tif', '5_1_2014_39.tif', '5_1_2014_41.tif', '5_1_2014_43.tif', '5_1_2014_45.tif']\n",
      "['5_1_2014_1.tif', '5_1_2014_3.tif', '5_1_2014_5.tif', '5_1_2014_7.tif', '5_1_2014_9.tif', '5_1_2014_11.tif', '5_1_2014_13.tif', '5_1_2014_15.tif', '5_1_2014_17.tif', '5_1_2014_19.tif', '5_1_2014_21.tif', '5_1_2014_23.tif', '5_1_2014_25.tif', '5_1_2014_27.tif', '5_1_2014_29.tif', '5_1_2014_31.tif', '5_1_2014_33.tif', '5_1_2014_35.tif', '5_1_2014_37.tif', '5_1_2014_39.tif', '5_1_2014_41.tif', '5_1_2014_43.tif', '5_1_2014_45.tif']\n",
      "['landsat_05_001_2014_1.tif', 'landsat_05_001_2014_2.tif', 'landsat_05_001_2014_3.tif', 'landsat_05_001_2014_4.tif', 'landsat_05_001_2014_5.tif', 'landsat_05_001_2014_6.tif', 'landsat_05_001_2014_7.tif', 'landsat_05_001_2014_8.tif', 'landsat_05_001_2014_9.tif', 'landsat_05_001_2014_10.tif', 'landsat_05_001_2014_11.tif', 'landsat_05_001_2014_12.tif', 'landsat_05_001_2014_13.tif', 'landsat_05_001_2014_14.tif', 'landsat_05_001_2014_15.tif', 'landsat_05_001_2014_16.tif', 'landsat_05_001_2014_17.tif', 'landsat_05_001_2014_18.tif', 'landsat_05_001_2014_19.tif', 'landsat_05_001_2014_20.tif', 'landsat_05_001_2014_21.tif', 'landsat_05_001_2014_22.tif', 'landsat_05_001_2014_23.tif']\n"
     ]
    }
   ],
   "source": [
    "# states=[5]\n",
    "# counties=[1,3,7,17,19,21,27,29,31,33,35,37,41,43,45,47,55,59,63,67,69,71,73,75,77,79,81,83,85,91,93,95,105,107,111,115,117,119,121,123,131,145,149]\n",
    "\n",
    "test_years = [2014]\n",
    "tst_year = test_years[0]\n",
    "start_year = 2014\n",
    "train_years = list (range(start_year,tst_year+1))\n",
    "val_years = [tst_year, tst_year]\n",
    "\n",
    "# print(val_years)\n",
    "\n",
    "def getModisName(state, county, year, step):\n",
    "    return str(state)+\"_\"+str(county)+\"_\"+str(year)+\"_\"+str(step)+\".tif\"\n",
    "def getLandsatName(state, county, year, step):\n",
    "    return \"landsat_\"+str(state).zfill(2)+\"_\"+str(county).zfill(3)+\"_\"+str(year)+\"_\"+str(step)+\".tif\"\n",
    "\n",
    "modis_train = []\n",
    "modis_val = []\n",
    "modis_test = []\n",
    "\n",
    "ls_train = []\n",
    "ls_val = []\n",
    "ls_test = []\n",
    "\n",
    "states_ls = process_state(dir_list_ls,'ls')\n",
    "states_md = process_state(dir_list_md,'md')\n",
    "\n",
    "states = common(states_ls,states_md)\n",
    "\n",
    "\n",
    "# print('state', states)\n",
    "for state in states:\n",
    "    counties_ls = process_county(dir_list_ls,state,'ls')\n",
    "    counties_md = process_county(dir_list_md,state,'md')\n",
    "    counties = common(counties_ls,counties_md)\n",
    "    for county in counties:\n",
    "        for year in range(start_year,(tst_year+1)):\n",
    "#             modis_filename_test=getModisName(state, county, year, step)\n",
    "#             landsat_filename_test=getLandsatName(state, county, year, step)\n",
    "            for step in range(1,47,2):\n",
    "                m_file=getModisName(state, county, year, step)\n",
    "                if year in train_years:\n",
    "                    modis_train.append(m_file)\n",
    "                if year in val_years:\n",
    "                    modis_val.append(m_file)\n",
    "                if year in test_years:\n",
    "                    modis_test.append(m_file)       \n",
    "            for step in range(1,24):\n",
    "                l_file=getLandsatName(state, county, year, step)\n",
    "                if year in train_years:\n",
    "                    ls_train.append(l_file)\n",
    "                if year in val_years:\n",
    "                    ls_val.append(l_file)\n",
    "                if year == tst_year:\n",
    "                    ls_test.append(l_file)             \n",
    "\n",
    "print(len(modis_train),len(modis_val),len(modis_test))\n",
    "print(len(ls_train),len(ls_val),len(ls_test))\n",
    "print(modis_train)\n",
    "print(modis_val)\n",
    "print(modis_test)\n",
    "print(ls_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_m = torchvision.transforms.Resize((256, 256),interpolation=T.InterpolationMode.NEAREST) ##original 150,250\n",
    "rc_l = torchvision.transforms.Resize((256, 256),interpolation=T.InterpolationMode.NEAREST) ##original (455, 575)\n",
    "\n",
    "# rc_m = torchvision.transforms.Pad(91, 115) ##original 150,250\n",
    "# rc_l = torchvision.transforms.Pad(2275, 2875) ##original 150,250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking(x,sat):\n",
    "#     x = torch.tensor(x)\n",
    "#     print(x.shape)\n",
    "#     xreshape = x.reshape(x.shape[0],x.shape[1],x.shape[2])\n",
    "#     print(xreshape.shape)\n",
    "#     print('nan',img, torch.isnan(xreshape).sum())\n",
    "#     print('inf',img, torch.isinf(xreshape).sum())\n",
    "#     print('minmax', img, torch.min(xreshape),torch.max(xreshape) ) \n",
    "    x = x.to(device)\n",
    "    xnan = torch.where(torch.isnan(x),0,x)\n",
    "    if sat =='ls':\n",
    "        xinf = torch.where(torch.isinf(xnan),1,xnan)\n",
    "    else:\n",
    "        xinf = torch.where(torch.isinf(xnan),5000,xnan)\n",
    "#     print('nan',img, torch.isnan(xnan).sum())  \n",
    "#     print('inf',img, torch.isinf(xnan).sum())      \n",
    "#     print('minmax', img, torch.min(xnan),torch.max(xnan) )      \n",
    "    cnnv= nn.AvgPool2d(kernel_size =3, stride=1, padding = 1, ceil_mode=False,count_include_pad=False)\n",
    "    cnnv = cnnv.to(device)\n",
    "    xinf = xinf.to(device)\n",
    "    output = cnnv(xinf)\n",
    "#     print(out.shape)\n",
    "#     resin = torch.where(torch.isnan(x),output,x)\n",
    "#     resin = torch.where(torch.isnan(x),xnan,x)\n",
    "#     resinf = torch.where(torch.isinf(resin),xinf,resin) \n",
    "    resin = torch.where(torch.isnan(x),output,x)\n",
    "    resinf = torch.where(torch.isinf(resin),output,resin) \n",
    "    res = torch.squeeze(resinf)\n",
    "#     res = res.numpy()\n",
    "#     print(res.shape)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, modis_path, modis_list, ls_path, ls_list):\n",
    "        self.modis_path = modis_path\n",
    "        self.modis_list = modis_list\n",
    "        self.ls_path    = ls_path\n",
    "        self.ls_list    = ls_list\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.modis_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        file_num = idx\n",
    "    \n",
    "        modis_file = self.modis_list[file_num]\n",
    "        ls_file    = self.ls_list[file_num]        \n",
    "        ls_file_prev = self.ls_list[file_num-1]\n",
    "        modis_img_path = os.path.join(self.modis_path, modis_file)\n",
    "        ls_img_path    = os.path.join(self.ls_path, ls_file) \n",
    "        ls_img_path_prev = os.path.join(self.ls_path, ls_file_prev)\n",
    "        modis_img = gdal.Open(modis_img_path).ReadAsArray()\n",
    "        ls_img = gdal.Open(ls_img_path).ReadAsArray() \n",
    "        ls_img_prev = gdal.Open(ls_img_path_prev).ReadAsArray()             \n",
    "        modis_img = modis_img/255\n",
    "        ls_img = ls_img/255\n",
    "        ls_img_prev = ls_img_prev/255      \n",
    "        \n",
    "        modis_img = np.array(modis_img)\n",
    "        ls_img    = np.array(ls_img)\n",
    "        ls_img_prev = np.array(ls_img_prev)\n",
    "\n",
    "        modis_img = torch.tensor(modis_img)\n",
    "        ls_img    = torch.tensor(ls_img)\n",
    "        ls_img_prev = torch.tensor(ls_img_prev)\n",
    "        modis_img = masking(modis_img, 'md')\n",
    "        ls_img = masking(ls_img, 'ls')\n",
    "        ls_img_prev = masking(ls_img_prev, 'ls')\n",
    "        modis_img = rc_m(modis_img)\n",
    "        ls_img    = rc_l(ls_img)\n",
    "        ls_img_prev = rc_l(ls_img_prev)\n",
    "        source = torch.cat((modis_img,ls_img_prev),0)    \n",
    "        return_value = [source,ls_img]     \n",
    "        return return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.3412, 0.3412, 0.8235],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.7882, 0.7882, 0.1294],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.5373, 0.5373, 0.7922],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       dtype=torch.float64), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomImageDataset(modis_folder,modis_train,landsat_folder,ls_train)\n",
    "\n",
    "\n",
    "fnames = ['modis',  'ls'] \n",
    "# print(dataset[0])\n",
    "item   = dataset[0]\n",
    "print(item)\n",
    "# print([(fnames[i],item[i].shape) for i in range(len(item))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.3412, 0.3412, 0.8235],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.7882, 0.7882, 0.1294],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.5373, 0.5373, 0.7922],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       dtype=torch.float64), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "train_data = CustomImageDataset(modis_folder,modis_train,landsat_folder,ls_train)\n",
    "val_data   = CustomImageDataset(modis_folder,modis_val,landsat_folder,ls_val)\n",
    "test_data  = CustomImageDataset(modis_folder,modis_test,landsat_folder,ls_test)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=1, shuffle=False)\n",
    "val_dataloader = DataLoader(val_data, batch_size=1, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(1, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(2, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(3, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(4, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(5, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(6, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(7, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(8, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(9, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(10, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(11, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(12, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(13, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(14, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(15, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(16, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(17, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(18, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(19, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(20, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(21, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n",
      "(22, torch.Size([1, 10, 256, 256]), torch.Size([1, 5, 256, 256]))\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (source, target)  in enumerate(train_dataloader):\n",
    "    x= (batch_idx, source.shape,  target.shape)\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6b3141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Conv2d(nn.Module):\n",
    "    \"\"\"Conv2d + BatchNorm + Dropout + ReLU\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input image\n",
    "        out_channels (int): Number of channels produced by the convolution\n",
    "        kernel_size (int or tuple): Size of the convolving kernel\n",
    "        stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
    "        padding (int or tuple, optional): Zero-padding added to both sides of the input. Default: 0\n",
    "        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
    "        relu (bool, str): if True, uses ReLU - if 'learn', uses PReLU\n",
    "        leak (float): if > 0 and relu == True, applies leaky ReLU instead\n",
    "        bn (bool): if True, uses batch normalization\n",
    "        dropout (float): dropout probability\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, bias=True, dilation=1, relu=False, leak=0.,\n",
    "                 dropout=0., bn=False):\n",
    "        super(Conv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels,\n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=kernel_size,\n",
    "                              stride=stride,\n",
    "                              padding=padding,\n",
    "                              dilation=dilation,\n",
    "                              bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=1e-5, momentum=0.1, affine=True) if bn else None\n",
    "        self.dropout = nn.Dropout(p=dropout, inplace=True) if dropout > 0 else None\n",
    "        if relu:\n",
    "            if leak > 0:\n",
    "                self.relu = nn.LeakyReLU(negative_slope=leak, inplace=True)\n",
    "            elif relu == 'learn':\n",
    "                self.relu = nn.PReLU()\n",
    "            elif relu is True:\n",
    "                self.relu = nn.ReLU(inplace=True)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown argument specified for ReLU activation\")\n",
    "        else:\n",
    "            self.relu = None\n",
    "\n",
    "        # Weights initializer\n",
    "        nn.init.xavier_normal_(self.conv.weight)\n",
    "        if self.conv.bias is not None:\n",
    "            nn.init.zeros_(self.conv.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn:\n",
    "            x = self.bn(x)\n",
    "        if self.dropout:\n",
    "            x = self.dropout(x)\n",
    "        if self.relu:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "    def output_size(self, input_size):\n",
    "        \"\"\"Computes output size\n",
    "        Args:\n",
    "            input_size (tuple): (C_in, H_in, W_in)\n",
    "        \"\"\"\n",
    "        _, H_in, W_in = input_size\n",
    "        C_out = self.conv.out_channels\n",
    "        kernel_size = self.conv.kernel_size[0]\n",
    "        padding = self.conv.padding[0]\n",
    "        stride = self.conv.stride[0]\n",
    "        H_out = int(np.floor((H_in - kernel_size + 2 * padding) / stride + 1))\n",
    "        W_out = int(np.floor((W_in - kernel_size + 2 * padding) / stride + 1))\n",
    "        return (C_out, H_out, W_out)\n",
    "\n",
    "\n",
    "class ConvTranspose2d(nn.Module):\n",
    "    \"\"\"Conv2d + BatchNorm + Dropout + ReLU\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input image\n",
    "        out_channels (int): Number of channels produced by the convolution\n",
    "        kernel_size (int or tuple): Size of the convolving kernel\n",
    "        stride (int or tuple, optional): stride for the cross-correlation. Default: 1\n",
    "        padding (int or tuple, optional): zero-padding will be added to both sides of each dimension in the inpu\n",
    "        output_padding (int or tuple, optional): controls the additional size added to one side of the output shape. Default: 0\n",
    "        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
    "        relu (bool, str): if True, uses ReLU - if 'learn', uses PReLU\n",
    "        leak (float): if > 0 and relu == True, applies leaky ReLU instead\n",
    "        dropout (float): dropout probability\n",
    "        bn (bool): if True, uses batch normalization\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=1, output_padding=0, bias=True, dilation=1, relu=False,\n",
    "                 leak=0., dropout=0., bn=False):\n",
    "        super(ConvTranspose2d, self).__init__()\n",
    "        self.conv = nn.ConvTranspose2d(in_channels=in_channels,\n",
    "                                       out_channels=out_channels,\n",
    "                                       kernel_size=kernel_size,\n",
    "                                       stride=stride,\n",
    "                                       padding=padding,\n",
    "                                       output_padding=output_padding,\n",
    "                                       dilation=dilation,\n",
    "                                       bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=1e-5, momentum=0.1, affine=True) if bn else None\n",
    "        self.dropout = nn.Dropout(p=dropout, inplace=True) if dropout > 0 else None\n",
    "        if relu:\n",
    "            if leak > 0:\n",
    "                self.relu = nn.LeakyReLU(negative_slope=leak, inplace=True)\n",
    "            elif relu == 'learn':\n",
    "                self.relu = nn.PReLU()\n",
    "            elif relu is True:\n",
    "                self.relu = nn.ReLU(inplace=True)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown argument specified for ReLU activation\")\n",
    "        else:\n",
    "            self.relu = None\n",
    "\n",
    "        # Weights initializer\n",
    "        nn.init.xavier_normal_(self.conv.weight)\n",
    "        if self.conv.bias is not None:\n",
    "            nn.init.zeros_(self.conv.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn:\n",
    "            x = self.bn(x)\n",
    "        if self.dropout:\n",
    "            x = self.dropout(x)\n",
    "        if self.relu:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "    def output_size(self, input_size):\n",
    "        \"\"\"Computes output size\n",
    "        Args:\n",
    "            input_size (tuple): (C, H_in, W_in)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    \"\"\"2D-Convolutional residual unit\n",
    "\n",
    "    # TODO : add ascii drawing of block\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input image\n",
    "        out_channels (int): Number of channels produced by the convolution\n",
    "        scaling (float): residual scaling factor\n",
    "        stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
    "        bias (bool): if True, uses bias parameter in convolutions\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1,\n",
    "                 padding=1, scaling=0.1, bias=False, leak=0.):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride,\n",
    "                            padding=padding, bias=bias, relu=True, leak=leak, bn=True)\n",
    "        self.conv2 = Conv2d(out_channels, out_channels, kernel_size=3, stride=1,\n",
    "                            padding=1, bias=bias, relu=False, bn=True)\n",
    "        self.adjust_identity = None\n",
    "        if stride > 1 or in_channels != out_channels:\n",
    "            self.adjust_identity = Conv2d(in_channels, out_channels, kernel_size=1, stride=stride,\n",
    "                                          bias=False, dilation=1, relu=False, bn=True)\n",
    "        self.scaling = scaling\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        buffer = self.conv1(x)\n",
    "        residual = self.conv2(buffer)\n",
    "\n",
    "        if self.adjust_identity is not None:\n",
    "            x = self.adjust_identity(x)\n",
    "\n",
    "        residual = residual.mul(self.scaling)\n",
    "        x = x.add(residual)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39063e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted, groundtruth, thresh=0.5):\n",
    "    \"\"\"Accuracy on single label classification\n",
    "    Args:\n",
    "        predicted (torch.Tensor): batch of probability distributions on classes\n",
    "        groundtruth (torch.Tensor): batch of probability distributions on classes\n",
    "    \"\"\"\n",
    "    predicted = predicted > thresh\n",
    "    correct = torch.sum(predicted.float() == groundtruth).float()\n",
    "    score = correct / groundtruth.numel()\n",
    "    return score.item()\n",
    "\n",
    "\n",
    "def precision(predicted, groundtruth, thresh=0.5):\n",
    "    \"\"\"Precision on single label classification\n",
    "    Args:\n",
    "        predicted (torch.Tensor): batch of probability distributions on classes\n",
    "        groundtruth (torch.Tensor): batch of probability distributions on classes\n",
    "    \"\"\"\n",
    "    positives = predicted > thresh\n",
    "    true_positives = torch.sum(positives[positives].float() == groundtruth[positives]).float()\n",
    "    precision = true_positives.div(positives.sum())\n",
    "    return precision.item()\n",
    "\n",
    "\n",
    "def recall(predicted, groundtruth, thresh=0.5):\n",
    "    \"\"\"Recall on single label classification\n",
    "    Args:\n",
    "        predicted (torch.Tensor): batch of probability distributions on classes\n",
    "        groundtruth (torch.Tensor): batch of probability distributions on classes\n",
    "    \"\"\"\n",
    "    predicted = predicted > thresh\n",
    "    positives = groundtruth == 1\n",
    "    true_positives = torch.sum(predicted[positives].float() == groundtruth[positives]).float()\n",
    "    recall = true_positives.div(positives.sum())\n",
    "    return recall.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6be5fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "from skimage import metrics\n",
    "\n",
    "\n",
    "def psnr(ref, tgt):\n",
    "    \"\"\"Computes peak signal to noise ratio of a target image wrt to a\n",
    "    reference image\n",
    "\n",
    "    Args:\n",
    "        ref (np.ndarray): Reference image as (height, width)\n",
    "        tgt (np.ndarray): Target image as (height, width)\n",
    "\n",
    "    Returns:\n",
    "        type: float\n",
    "\n",
    "    \"\"\"\n",
    "    return metrics.peak_signal_noise_ratio(image_true=ref,\n",
    "                                           image_test=tgt)\n",
    "\n",
    "\n",
    "def ssim(ref, tgt, window_size=None):\n",
    "    \"\"\"Computes mean structural similarity index between two images\n",
    "\n",
    "    \"Image quality assessment: from error visibility to structural similarity\",\n",
    "    Wang et. al 2004\n",
    "\n",
    "    Args:\n",
    "        ref (np.ndarray): Reference image as (height, width)\n",
    "        tgt (np.ndarray): Target image as (height, width)\n",
    "        window_size (int): side-length of the sliding window used in comparison\n",
    "            must be odd value (default: None)\n",
    "\n",
    "    Returns:\n",
    "        type: float\n",
    "\n",
    "    \"\"\"\n",
    "    return metrics.structural_similarity(im1=ref,\n",
    "                                         im2=tgt,\n",
    "                                         win_size=window_size,data_range=tgt.max()-tgt.min())\n",
    "\n",
    "\n",
    "def sam(ref, tgt, reduce=None):\n",
    "    \"\"\"Computes normalized Spectrale Angle Mapper as introduced in\n",
    "\n",
    "    \"Discrimination among semi-arid landscape endmembers using the spectral\n",
    "    angle mapper (SAM) algorithm\", Boardman et al. 1993\n",
    "\n",
    "    Args:\n",
    "        ref (np.ndarray): Reference image as (height, width, channels)\n",
    "        tgt (np.ndarray): Target image as (height, width, channels)\n",
    "        reduce (str): output reduction method\n",
    "\n",
    "    Returns:\n",
    "        type: {np.ndarray, float}\n",
    "    \"\"\"\n",
    "    # Compute pixelwise bands inner product\n",
    "    kernel = np.einsum('...k,...k', ref, tgt)\n",
    "\n",
    "    # Normalize inner products\n",
    "    square_norm_ref = np.einsum('...k,...k', ref, ref).clip(min=np.finfo(np.float16).eps)\n",
    "    square_norm_tgt = np.einsum('...k,...k', tgt, tgt).clip(min=np.finfo(np.float16).eps)\n",
    "    normalized_kernel = kernel / np.sqrt(square_norm_ref * square_norm_tgt)\n",
    "\n",
    "    # Convert to angles\n",
    "    normalized_angles = np.arccos(normalized_kernel.clip(min=-1, max=1)) / np.pi\n",
    "    if not reduce:\n",
    "        output = normalized_angles\n",
    "    elif reduce == 'mean':\n",
    "        output = normalized_angles.mean()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown reduce method\")\n",
    "    return output\n",
    "\n",
    "\n",
    "def cw_ssim(ref, tgt, width=30, K=0.01):\n",
    "    \"\"\"Compute the complex wavelet SSIM (CW-SSIM) value from the reference\n",
    "    image to the target image.\n",
    "\n",
    "    \"CW-SSIM based image classification\", Gao et. al 2011\n",
    "\n",
    "    Code based on https://github.com/jterrace/pyssim/blob/master/ssim/ssimlib.py\n",
    "\n",
    "    Args:\n",
    "      ref (np.ndarray): Reference image as (height, width)\n",
    "      tgt (np.ndarray): Target image as (height, width)\n",
    "      width (int): width for the wavelet convolution (default: 30)\n",
    "      K (float): small algorithm parameter (default: 0.01)\n",
    "    Returns:\n",
    "      type: float\n",
    "    \"\"\"\n",
    "    # Define a width for the wavelet convolution\n",
    "    widths = np.arange(1, width + 1)\n",
    "\n",
    "    # Convolution\n",
    "    cwt1 = signal.cwt(ref.flatten(), signal.ricker, widths)\n",
    "    cwt2 = signal.cwt(tgt.flatten(), signal.ricker, widths)\n",
    "\n",
    "    # Compute the first term\n",
    "    c1c2 = np.abs(cwt1) * np.abs(cwt2)\n",
    "    c1_2 = np.square(np.abs(cwt1))\n",
    "    c2_2 = np.square(np.abs(cwt2))\n",
    "    numerator_ssim1 = 2 * c1c2.sum(axis=0) + K\n",
    "    denominator_ssim1 = c1_2.sum(axis=0) + c2_2.sum(axis=0) + K\n",
    "\n",
    "    # Compute the second term\n",
    "    c1c2_conj = cwt1 * np.conjugate(cwt2)\n",
    "    numerator_ssim2 = 2 * np.abs(c1c2_conj.sum(axis=0)) + K\n",
    "    denominator_ssim2 = 2 * np.abs(c1c2_conj).sum(axis=0) + K\n",
    "\n",
    "    # Construct the result\n",
    "    ssim_map = (numerator_ssim1 / denominator_ssim1) * (numerator_ssim2 / denominator_ssim2)\n",
    "\n",
    "    # Average the per pixel results\n",
    "    index = np.mean(ssim_map)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbf82d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_classification_metrics(output_real_sample, output_fake_sample):\n",
    "        \"\"\"Computes metrics on discriminator classification power : fooling rate\n",
    "            of generator, precision and recall\n",
    "\n",
    "        Args:\n",
    "            output_real_sample (torch.Tensor): discriminator prediction on real samples\n",
    "            output_fake_sample (torch.Tensor): discriminator prediction on fake samples\n",
    "\n",
    "        Returns:\n",
    "            type: tuple[float]\n",
    "        \"\"\"\n",
    "        # Setup complete outputs and targets vectors\n",
    "        target_real_sample = torch.ones_like(output_real_sample)\n",
    "        target_fake_sample = torch.zeros_like(output_fake_sample)\n",
    "        output = torch.cat([output_real_sample, output_fake_sample])\n",
    "        target = torch.cat([target_real_sample, target_fake_sample])\n",
    "\n",
    "        # Compute generator and discriminator metrics\n",
    "        fooling_rate = accuracy(output_fake_sample, target_real_sample)\n",
    "        precision1 = precision(output, target)\n",
    "        recall1 = recall(output, target)\n",
    "        return fooling_rate, precision1, recall1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ad4cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "def _compute_iqa_metrics(estimated_target, target, reduction=None):\n",
    "        \"\"\"Computes full reference image quality assessment metrics : psnr, ssim\n",
    "            and spectral angle mapper (see evaluation/metrics/iqa.py for details)\n",
    "\n",
    "        Args:\n",
    "            estimated_target (torch.Tensor): generated sample\n",
    "            target (torch.Tensor): target sample\n",
    "\n",
    "        Returns:\n",
    "            type: tuple[float]\n",
    "        \"\"\"\n",
    "        # Reshape as (batch_size * channels, height, width) to run single for loop\n",
    "        batch_size, channels, height, width = target.shape\n",
    "        estimated_target = estimated_target.clamp(min=0).detach().cpu().numpy()\n",
    "        target = target.clamp(min=0).detach().cpu().numpy()\n",
    "        estimated_bands = estimated_target.reshape(-1, height, width)\n",
    "        target_bands = target.reshape(-1, height, width)\n",
    "\n",
    "        # Compute IQA metrics by band\n",
    "        iqa_metrics = defaultdict(list)\n",
    "        for src, tgt in zip(estimated_bands, target_bands):\n",
    "            data_range = np.max([src, tgt])\n",
    "            src = src / data_range\n",
    "            tgt = tgt / data_range\n",
    "            iqa_metrics['psnr'] += [psnr(tgt, src)]\n",
    "            iqa_metrics['ssim'] += [ssim(tgt, src)]\n",
    "\n",
    "        # Average bandwise - reduce if needed\n",
    "        psnr1 = np.asarray(iqa_metrics['psnr']).reshape(batch_size, channels).mean(axis=0)\n",
    "        ssim1 = np.asarray(iqa_metrics['ssim']).reshape(batch_size, channels).mean(axis=0)\n",
    "        if reduction == 'mean':\n",
    "            psnr1 = psnr1.mean()\n",
    "            ssim1 = ssim1.mean()\n",
    "\n",
    "        # Compute average spectral angle mapper\n",
    "        estimated_target = estimated_target.transpose(0, 2, 3, 1).astype(np.float32)\n",
    "        target = target.transpose(0, 2, 3, 1).astype(np.float32)\n",
    "        sam1 = sam(target, estimated_target).mean()\n",
    "        return psnr1, ssim1, sam1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "###   for bigger size of landsat ###########\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,landsat_inc):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        #Encoder\n",
    "        self.conv1 = Conv2d(landsat_inc*2,64,4,2,1,bn=False,relu=False)\n",
    "        print(self.conv1)\n",
    "        self.conv2 = Conv2d(64,128,4,2,1,bn=True,relu=\"learn\")\n",
    "        self.conv3 = Conv2d(128,256,4,2,1,bn=True,relu=\"learn\")\n",
    "        self.conv4 = Conv2d(256,512,4,2,1,bn=True,relu=\"learn\")\n",
    "        self.conv5 = Conv2d(512,1024,4,2,1,bn=True,relu=\"learn\")\n",
    "        self.conv6 = Conv2d(1024,1024,4,1,1,bn=True,relu=\"learn\")\n",
    "        \n",
    "        # Decoder\n",
    "        self.conv7 = ConvTranspose2d(1024,1024,2,1,0,dropout=0.4,bn=True,relu=\"learn\")\n",
    "        self.conv8 = ConvTranspose2d(1024,512,4,2,1,bn=True,dropout=0.4,relu=\"learn\")\n",
    "        self.conv9 = ConvTranspose2d(512,256,4,2,1,bn=True, relu=\"learn\")\n",
    "        self.conv10 = ConvTranspose2d(256,128,4,2,1,bn=True, relu=\"learn\")\n",
    "        self.conv11 = ConvTranspose2d(128,64,4,2,1,bn=True, relu=\"learn\")\n",
    "        self.conv12 = ConvTranspose2d(64,64,4,2,1,bn=False, relu=False)\n",
    "\n",
    "        #Output layer\n",
    "        self.conv13 = Conv2d(64,5,3,padding=1)\n",
    "                                 \n",
    "                                        \n",
    " \n",
    "    def forward(self, input):\n",
    "#         x = F.relu(self.conv1(input))\n",
    "# #         print('conv1', x.shape)\n",
    "#         x = self.bn1(x)\n",
    "        \n",
    "#         x = F.relu(self.conv2(x))\n",
    "# #         print('conv2', x.shape)\n",
    "#         x = self.bn1(x)\n",
    "        \n",
    "#         x = F.relu(self.conv3(x))\n",
    "# #         print('conv3', x.shape)\n",
    "#         x = self.bn1(x)\n",
    "        \n",
    "#         x = F.relu(self.conv4(x))\n",
    "# #         print('conv4', x.shape)\n",
    "#         x = self.bn1(x)\n",
    "        \n",
    "        \n",
    "#         x = F.relu(self.conv5(x))\n",
    "# #         print('conv4', x.shape)\n",
    "#         x = self.bn1(x)        \n",
    "        \n",
    "#         x = F.relu(self.conv6(x))\n",
    "# #         print('conv5', x.shape)\n",
    "#         output = self.bn1(x)        \n",
    "#         sigmoid = nn.Sigmoid()    \n",
    "#         output = sigmoid(output)         \n",
    "        \n",
    "        # print(input.shape)\n",
    "\n",
    "        x = self.conv1(input)\n",
    "        # print('conv1', x.shape)\n",
    "        x = self.conv2(x)\n",
    "        # print('conv2', x.shape)\n",
    "        x = self.conv3(x)\n",
    "        # print('conv3', x.shape)\n",
    "        x = self.conv4(x)\n",
    "        # print('conv4', x.shape)\n",
    "        x = self.conv5(x)\n",
    "        # print('conv5', x.shape)\n",
    "        x = self.conv6(x)\n",
    "        # print('conv6', x.shape)\n",
    "        x = self.conv7(x)\n",
    "        # print('conv7', x.shape)\n",
    "        x = self.conv8(x)\n",
    "        # print('conv8', x.shape)\n",
    "        x = self.conv9(x)\n",
    "        # print('conv9', x.shape)\n",
    "        x = self.conv10(x)\n",
    "        # print('conv10', x.shape)\n",
    "        x = self.conv11(x)\n",
    "        # print('conv11', x.shape)\n",
    "        x = self.conv12(x)\n",
    "        # print('conv12',x.shape)\n",
    "        output = self.conv13(x)\n",
    "        # print('conv13', output.shape)\n",
    "        \n",
    "        return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "###   for smaller size of landsat ###########\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,landsat_inc):\n",
    "        super(Discriminator, self).__init__()                               \n",
    "        self.conv1 = Conv2d(landsat_inc*3,128,4,2,1,bn=False,relu=True,leak=0.2)\n",
    "        self.conv2 = Conv2d(128,256,4,2,1,bn=True,relu=True,leak=0.2)\n",
    "        self.conv3 = Conv2d(256,512,4,2,1,bn=True,relu=True,leak=0.2)\n",
    "        self.conv4 = Conv2d(512,512,4,2,1,bn=True,relu=True,leak=0.2)\n",
    "        self.conv5 = Conv2d(512,1,4,1,1,bn=False,relu=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, source,x):\n",
    "#         print('dis input xnan', torch.isnan(x).sum())\n",
    "#         print('dis input ynan', torch.isnan(y).sum())        \n",
    "#         x = normalize(x)\n",
    "#         y = normalize(y)        \n",
    "        \n",
    "        # x = F.relu(self.conv1(x))\n",
    "        # y = F.relu(self.conv1(y))        \n",
    "#         print('conv1', x.shape,y.shape)\n",
    "        # x = self.bn1(x)\n",
    "        # y = self.bn1(y)        \n",
    "        \n",
    "        # x = F.relu(self.conv2(x))\n",
    "        # y = F.relu(self.conv2(y))         \n",
    "#         print('conv2', x.shape,y.shape)\n",
    "        # x = self.bn1(x)\n",
    "        # y = self.bn1(y) \n",
    "        \n",
    "        # x = F.relu(self.conv3(x))\n",
    "        # y = F.relu(self.conv3(y))         \n",
    "#         print('conv3', x.shape,y.shape)\n",
    "        # x = self.bn1(x)\n",
    "        # y = self.bn1(y) \n",
    "        \n",
    "        # x_out = self.flt(x)\n",
    "        # y_out = self.flt(y)       \n",
    "#         print('flt', x_out.shape,y_out.shape)        \n",
    "\n",
    "        \n",
    "        # flt_out = torch.cat((x_out, y_out), 1)\n",
    "#         print('fltout', flt_out.shape)         \n",
    "#         x = F.relu(self.conv4(x))\n",
    "#         print('conv4', x.shape)\n",
    "#         x = self.bn1(x)\n",
    "        \n",
    "        \n",
    "#         x = F.relu(self.conv5(x))\n",
    "#         print('conv4', x.shape)\n",
    "#         x = self.bn1(x)        \n",
    "        \n",
    "#         x = F.relu(self.conv6(x))\n",
    "#         print('conv5', x.shape)\n",
    "        # fc_out = self.fc1(flt_out)\n",
    "#         print('fc_out',fc_out.shape)\n",
    "        \n",
    "        # sigmoid = nn.Sigmoid()\n",
    "        # output = sigmoid(fc_out)  \n",
    "#         print('output',output.shape)\n",
    "        # print('x',x.shape)\n",
    "        # print('source',source.shape)\n",
    "        x = torch.cat((x,source),dim=1)\n",
    "        # print('x',x.shape)\n",
    "        x = self.conv1(x)\n",
    "        # print('x',x.shape)\n",
    "        x = self.conv2(x)\n",
    "        # print('x',x.shape)\n",
    "        x = self.conv3(x)\n",
    "        # print('x',x.shape)\n",
    "        x = self.conv4(x)\n",
    "        # print('x',x.shape)\n",
    "        output = self.conv5(x)\n",
    "        # print('output',output.shape)\n",
    "        output = self.sigmoid(output)\n",
    "        # print('output',output.shape)\n",
    "        \n",
    "        return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_gen = 'saved_models/gen'\n",
    "path_to_dis = 'saved_models/dis'\n",
    "\n",
    "# path_to_output = '../../../saved_outputs/landsat8_corn_2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gan(gen, dis, data_loader, dataset):\n",
    "    \n",
    "    gen.eval()\n",
    "    dis.eval()\n",
    "    \n",
    "    batch_count = 0\n",
    "    batch_gen_cGAN_loss = 0\n",
    "    batch_gen_L1_loss = 0\n",
    "    batch_gen_eval_loss = 0\n",
    "    batch_dis_fake_loss = 0\n",
    "    batch_dis_real_loss = 0\n",
    "    batch_dis_eval_loss = 0\n",
    "    gen_loss_eval = 0\n",
    "    dis_loss_eval = 0\n",
    "    batch_fooling_rate = 0\n",
    "    batch_precision = 0\n",
    "    batch_recall = 0\n",
    "    batch_psnr = 0\n",
    "    batch_ssim = 0\n",
    "    batch_sam = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target =  (data.float()).to(device),target.float().to(device)\n",
    "            \n",
    "\n",
    "            dis_result_fake = dis(data, target)\n",
    "            dis_real_loss = cGAN_loss(dis_result_fake, Variable((torch.zeros_like(dis_result_fake)).to(device)))\n",
    "            \n",
    "            gen_result = gen(data)\n",
    "            dis_result = dis(data, gen_result)\n",
    "            dis_fake_loss = cGAN_loss(dis_result, Variable((torch.rand(dis_result.size())*(1-0.8) + 0.8).to(device)))\n",
    "            fooling_rate, precision, recall = _compute_classification_metrics(dis_result,dis_result_fake)\n",
    "            batch_fooling_rate += fooling_rate\n",
    "            batch_precision += precision\n",
    "            batch_recall += recall\n",
    "            dis_eval_loss = (dis_real_loss + dis_fake_loss)#/2.0\n",
    "            \n",
    "            gen_result = gen(data)\n",
    "            dis_result = dis(data, gen_result)\n",
    "            gen_eval_cGAN_loss = cGAN_loss(dis_result, Variable(torch.ones_like(dis_result).to(device)))\n",
    "            gen_eval_L1_loss = gen_lambda * F.smooth_l1_loss(gen_result, target)\n",
    "            gen_eval_loss = gen_eval_cGAN_loss + gen_eval_L1_loss\n",
    "            psnr,ssim,sam = _compute_iqa_metrics(gen_result, target, reduction='mean')\n",
    "            batch_psnr += psnr\n",
    "            batch_ssim += ssim\n",
    "            batch_sam += sam\n",
    "            batch_count += 1;\n",
    "            batch_gen_cGAN_loss += gen_eval_cGAN_loss\n",
    "            batch_gen_eval_loss += gen_eval_loss\n",
    "            \n",
    "            \n",
    "            \n",
    "            batch_dis_fake_loss += dis_fake_loss\n",
    "            batch_dis_real_loss += dis_real_loss\n",
    "            batch_dis_eval_loss += dis_eval_loss\n",
    "            \n",
    "    gen_loss_eval = batch_gen_eval_loss/batch_count\n",
    "    dis_loss_eval = batch_dis_eval_loss/batch_count    \n",
    "    batch_fooling_rate = batch_fooling_rate/batch_count\n",
    "    batch_precision = batch_precision/batch_count\n",
    "    batch_recall = batch_recall/batch_count\n",
    "    batch_psnr = batch_psnr/batch_count\n",
    "    batch_ssim = batch_ssim/batch_count\n",
    "    batch_sam = batch_sam/batch_count\n",
    "    print('{} set: gen_loss: {}, dis_loss: {}\\ndis_fooling_rate: {}, dis_precision: {}, dis_recall: {}\\ngen_psnr: {}, gen_ssim: {}, gen_sam: {}\\n'.format(dataset, gen_loss_eval, dis_loss_eval, batch_fooling_rate, batch_precision, batch_recall, batch_psnr, batch_ssim, batch_sam))\n",
    "    if dataset == 'Validation':\n",
    "      return gen_loss_eval, dis_loss_eval\n",
    "    if dataset == 'Test':\n",
    "      return gen_loss_eval, dis_loss_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(gen, dis, opt_gen, opt_dis, epcs):\n",
    "    for epoch in range(1, epcs+1):\n",
    "        print('epoch', epoch)\n",
    "        gen.train()\n",
    "        dis.train()\n",
    "        for batch_idx,(data,target) in enumerate(train_dataloader):\n",
    "            data, target  = (data.float()).to(device), target.float().to(device)\n",
    "            dis.zero_grad()\n",
    "            gen_result = gen(data)\n",
    "            dis_result_fake = dis(data, gen_result)          \n",
    "            dis_fake_loss = cGAN_loss(dis_result_fake, Variable((torch.zeros_like(dis_result_fake)).to(device)))\n",
    "            dis_result = dis(data, target)\n",
    "            dis_real_loss = cGAN_loss(dis_result, Variable((torch.rand(dis_result.size())*(1-0.8) + 0.8).to(device)))\n",
    "            dis_train_loss = (dis_real_loss + dis_fake_loss)#/2.0\n",
    "            print('dis_train_loss',dis_train_loss)           \n",
    "            fooling_rate, precision, recall = _compute_classification_metrics(dis_result,dis_result_fake)\n",
    "            dis_train_loss.backward()\n",
    "            opt_dis.step()\n",
    "            gen.zero_grad()\n",
    "            gen_result = gen(data)\n",
    "            dis_result = dis(data, gen_result)\n",
    "            gen_train_cGAN_loss = cGAN_loss(dis_result, Variable(torch.ones_like(dis_result).to(device)))\n",
    "            gen_train_L1_loss = gen_lambda * F.smooth_l1_loss(gen_result, target)\n",
    "            gen_train_loss = gen_train_cGAN_loss + gen_train_L1_loss\n",
    "            psnr,ssim,sam = _compute_iqa_metrics(gen_result, target, reduction='mean')\n",
    "            print('gen_train_loss',gen_train_loss) \n",
    "            gen_train_loss.backward()\n",
    "            opt_gen.step()\n",
    "        gen_lr_scheduler.step()\n",
    "        disc_lr_scheduler.step()\n",
    "\n",
    "        if (epoch>0):\n",
    "            torch.save(gen, os.path.join(path_to_gen, \"gen_%d.pt\"%(epoch)))\n",
    "            torch.save(dis, os.path.join(path_to_dis, \"dis_%d.pt\"%(epoch)))\n",
    "        print('Train Epoch: {} Training gen Loss: {} dis Loss: {}'.format(epoch,gen_train_loss.item(),dis_train_loss.item()))\n",
    "        gen_val_loss, dis_val_loss = evaluate_gan(gen, dis,val_dataloader,'Validation')\n",
    "    return  gen_train_loss, dis_train_loss, gen_val_loss, dis_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(module):\n",
    "    if type(module) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(module.weight)\n",
    "        # torch.nn.init.xavier_normal_(module.weight, gain = 1.0)        \n",
    "        module.bias.data.fill_(0.001)\n",
    "    if type(module) == nn.Conv2d:    \n",
    "        torch.nn.init.xavier_uniform(module.weight)\n",
    "        module.bias.data.fill_(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_inc = 5\n",
    "\n",
    "# seq_length = len(timesteps)\n",
    "hidden_dim = 20\n",
    "epochs = 10   # 75\n",
    "n_layers = 1\n",
    "output_dim = 1\n",
    "\n",
    "dp = 0.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(\n",
      "  (conv): Conv2d(10, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# timesteps, hidden_dim,sl, out_dim\n",
    "\n",
    "gen = Generator(landsat_inc).to(device)\n",
    "dis = Discriminator(landsat_inc).to(device)\n",
    "\n",
    "# gen.apply(init_weights)\n",
    "# dis.apply(init_weights)\n",
    "\n",
    "cGAN_loss = nn.BCELoss().to(device)\n",
    "gen_lambda = 0.1\n",
    "\n",
    "opt_gen = torch.optim.Adam(gen.parameters(), lr=0.0003, betas=[0.5,0.999])\n",
    "opt_dis = torch.optim.Adam(dis.parameters(), lr=0.0003, betas=[0.5,0.999], weight_decay=0.000001)\n",
    "gen_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(opt_gen, gamma=0.99)\n",
    "disc_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(opt_dis, gamma=0.99)\n",
    "\n",
    "# optimizer = optim.SGD(model_vims.parameters(), lr=0.0001, weight_decay = 0.00001, momentum = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "batch_idx 0\n",
      "dis_train_loss tensor(1.5763, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(3.0178, grad_fn=<AddBackward0>)\n",
      "batch_idx 1\n",
      "dis_train_loss tensor(3.8015, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.7703, grad_fn=<AddBackward0>)\n",
      "batch_idx 2\n",
      "dis_train_loss tensor(3.5406, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(2.2063, grad_fn=<AddBackward0>)\n",
      "batch_idx 3\n",
      "dis_train_loss tensor(2.9830, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.4648, grad_fn=<AddBackward0>)\n",
      "batch_idx 4\n",
      "dis_train_loss tensor(1.9150, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0576, grad_fn=<AddBackward0>)\n",
      "batch_idx 5\n",
      "dis_train_loss tensor(2.0524, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.5870, grad_fn=<AddBackward0>)\n",
      "batch_idx 6\n",
      "dis_train_loss tensor(2.3278, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.3015, grad_fn=<AddBackward0>)\n",
      "batch_idx 7\n",
      "dis_train_loss tensor(1.7712, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2510, grad_fn=<AddBackward0>)\n",
      "batch_idx 8\n",
      "dis_train_loss tensor(1.6686, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2527, grad_fn=<AddBackward0>)\n",
      "batch_idx 9\n",
      "dis_train_loss tensor(1.4909, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1742, grad_fn=<AddBackward0>)\n",
      "batch_idx 10\n",
      "dis_train_loss tensor(1.6020, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.5187, grad_fn=<AddBackward0>)\n",
      "batch_idx 11\n",
      "dis_train_loss tensor(1.6051, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0621, grad_fn=<AddBackward0>)\n",
      "batch_idx 12\n",
      "dis_train_loss tensor(1.4510, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0239, grad_fn=<AddBackward0>)\n",
      "batch_idx 13\n",
      "dis_train_loss tensor(1.4318, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1453, grad_fn=<AddBackward0>)\n",
      "batch_idx 14\n",
      "dis_train_loss tensor(1.3803, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2489, grad_fn=<AddBackward0>)\n",
      "batch_idx 15\n",
      "dis_train_loss tensor(1.3966, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1150, grad_fn=<AddBackward0>)\n",
      "batch_idx 16\n",
      "dis_train_loss tensor(1.4273, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2861, grad_fn=<AddBackward0>)\n",
      "batch_idx 17\n",
      "dis_train_loss tensor(1.4585, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0283, grad_fn=<AddBackward0>)\n",
      "batch_idx 18\n",
      "dis_train_loss tensor(1.5261, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.5642, grad_fn=<AddBackward0>)\n",
      "batch_idx 19\n",
      "dis_train_loss tensor(1.4797, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0662, grad_fn=<AddBackward0>)\n",
      "batch_idx 20\n",
      "dis_train_loss tensor(1.4248, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1544, grad_fn=<AddBackward0>)\n",
      "batch_idx 21\n",
      "dis_train_loss tensor(1.4880, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0776, grad_fn=<AddBackward0>)\n",
      "batch_idx 22\n",
      "dis_train_loss tensor(1.4797, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1222, grad_fn=<AddBackward0>)\n",
      "Train Epoch: 1 Training gen Loss: 1.1221508979797363 dis Loss: 1.4797484874725342\n",
      "Validation set: gen_loss: 0.4762229919433594, dis_loss: 1.3707249164581299\n",
      "dis_fooling_rate: 0.4769082140663396, dis_precision: 0.6271898383679597, dis_recall: 0.838454108523286\n",
      "gen_psnr: 17.323641669346, gen_ssim: 0.05619585781310267, gen_sam: 0.38072939022727637\n",
      "\n",
      "epoch 2\n",
      "batch_idx 0\n",
      "dis_train_loss tensor(1.4654, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0395, grad_fn=<AddBackward0>)\n",
      "batch_idx 1\n",
      "dis_train_loss tensor(1.4325, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0380, grad_fn=<AddBackward0>)\n",
      "batch_idx 2\n",
      "dis_train_loss tensor(1.3275, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1704, grad_fn=<AddBackward0>)\n",
      "batch_idx 3\n",
      "dis_train_loss tensor(1.3325, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2163, grad_fn=<AddBackward0>)\n",
      "batch_idx 4\n",
      "dis_train_loss tensor(1.3469, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0612, grad_fn=<AddBackward0>)\n",
      "batch_idx 5\n",
      "dis_train_loss tensor(1.4780, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1440, grad_fn=<AddBackward0>)\n",
      "batch_idx 6\n",
      "dis_train_loss tensor(1.3731, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1455, grad_fn=<AddBackward0>)\n",
      "batch_idx 7\n",
      "dis_train_loss tensor(1.3926, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0194, grad_fn=<AddBackward0>)\n",
      "batch_idx 8\n",
      "dis_train_loss tensor(1.5202, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0049, grad_fn=<AddBackward0>)\n",
      "batch_idx 9\n",
      "dis_train_loss tensor(1.3169, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0416, grad_fn=<AddBackward0>)\n",
      "batch_idx 10\n",
      "dis_train_loss tensor(1.3112, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2048, grad_fn=<AddBackward0>)\n",
      "batch_idx 11\n",
      "dis_train_loss tensor(1.3632, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8594, grad_fn=<AddBackward0>)\n",
      "batch_idx 12\n",
      "dis_train_loss tensor(1.4400, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1760, grad_fn=<AddBackward0>)\n",
      "batch_idx 13\n",
      "dis_train_loss tensor(1.3065, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1569, grad_fn=<AddBackward0>)\n",
      "batch_idx 14\n",
      "dis_train_loss tensor(1.2513, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1115, grad_fn=<AddBackward0>)\n",
      "batch_idx 15\n",
      "dis_train_loss tensor(1.2904, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1426, grad_fn=<AddBackward0>)\n",
      "batch_idx 16\n",
      "dis_train_loss tensor(1.2157, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2762, grad_fn=<AddBackward0>)\n",
      "batch_idx 17\n",
      "dis_train_loss tensor(1.1784, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2277, grad_fn=<AddBackward0>)\n",
      "batch_idx 18\n",
      "dis_train_loss tensor(1.1646, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.4496, grad_fn=<AddBackward0>)\n",
      "batch_idx 19\n",
      "dis_train_loss tensor(1.1596, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9990, grad_fn=<AddBackward0>)\n",
      "batch_idx 20\n",
      "dis_train_loss tensor(1.3972, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.7872, grad_fn=<AddBackward0>)\n",
      "batch_idx 21\n",
      "dis_train_loss tensor(1.5044, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2073, grad_fn=<AddBackward0>)\n",
      "batch_idx 22\n",
      "dis_train_loss tensor(1.2778, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1304, grad_fn=<AddBackward0>)\n",
      "Train Epoch: 2 Training gen Loss: 1.1304242610931396 dis Loss: 1.2778098583221436\n",
      "Validation set: gen_loss: 0.7915006875991821, dis_loss: 1.3614118099212646\n",
      "dis_fooling_rate: 0.312463764263236, dis_precision: 0.6516045915043872, dis_recall: 0.5619323694187662\n",
      "gen_psnr: 16.542826464387556, gen_ssim: 0.04188382378943554, gen_sam: 0.35549797052922455\n",
      "\n",
      "epoch 3\n",
      "batch_idx 0\n",
      "dis_train_loss tensor(1.3409, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1783, grad_fn=<AddBackward0>)\n",
      "batch_idx 1\n",
      "dis_train_loss tensor(1.2449, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1945, grad_fn=<AddBackward0>)\n",
      "batch_idx 2\n",
      "dis_train_loss tensor(1.2370, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.3888, grad_fn=<AddBackward0>)\n",
      "batch_idx 3\n",
      "dis_train_loss tensor(1.2540, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.5318, grad_fn=<AddBackward0>)\n",
      "batch_idx 4\n",
      "dis_train_loss tensor(1.2681, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9465, grad_fn=<AddBackward0>)\n",
      "batch_idx 5\n",
      "dis_train_loss tensor(1.4558, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.4059, grad_fn=<AddBackward0>)\n",
      "batch_idx 6\n",
      "dis_train_loss tensor(1.2590, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.5456, grad_fn=<AddBackward0>)\n",
      "batch_idx 7\n",
      "dis_train_loss tensor(1.2745, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1095, grad_fn=<AddBackward0>)\n",
      "batch_idx 8\n",
      "dis_train_loss tensor(1.4819, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2854, grad_fn=<AddBackward0>)\n",
      "batch_idx 9\n",
      "dis_train_loss tensor(1.2885, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9750, grad_fn=<AddBackward0>)\n",
      "batch_idx 10\n",
      "dis_train_loss tensor(1.3605, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2943, grad_fn=<AddBackward0>)\n",
      "batch_idx 11\n",
      "dis_train_loss tensor(1.2984, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2955, grad_fn=<AddBackward0>)\n",
      "batch_idx 12\n",
      "dis_train_loss tensor(1.2258, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2780, grad_fn=<AddBackward0>)\n",
      "batch_idx 13\n",
      "dis_train_loss tensor(1.1394, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.4969, grad_fn=<AddBackward0>)\n",
      "batch_idx 14\n",
      "dis_train_loss tensor(1.0264, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.3033, grad_fn=<AddBackward0>)\n",
      "batch_idx 15\n",
      "dis_train_loss tensor(1.1371, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.7712, grad_fn=<AddBackward0>)\n",
      "batch_idx 16\n",
      "dis_train_loss tensor(1.2026, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.7975, grad_fn=<AddBackward0>)\n",
      "batch_idx 17\n",
      "dis_train_loss tensor(1.4854, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2650, grad_fn=<AddBackward0>)\n",
      "batch_idx 18\n",
      "dis_train_loss tensor(1.3801, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.4521, grad_fn=<AddBackward0>)\n",
      "batch_idx 19\n",
      "dis_train_loss tensor(1.4465, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.3223, grad_fn=<AddBackward0>)\n",
      "batch_idx 20\n",
      "dis_train_loss tensor(1.3241, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1188, grad_fn=<AddBackward0>)\n",
      "batch_idx 21\n",
      "dis_train_loss tensor(1.4726, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0090, grad_fn=<AddBackward0>)\n",
      "batch_idx 22\n",
      "dis_train_loss tensor(1.4008, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.5041, grad_fn=<AddBackward0>)\n",
      "Train Epoch: 3 Training gen Loss: 1.5041285753250122 dis Loss: 1.4008466005325317\n",
      "Validation set: gen_loss: 1.9116969108581543, dis_loss: 2.2474892139434814\n",
      "dis_fooling_rate: 0.2778743971949038, dis_precision: 0.21046474187270456, dis_recall: 0.07439613552845042\n",
      "gen_psnr: 16.873439302860955, gen_ssim: 0.042479675130574275, gen_sam: 0.33417677879333496\n",
      "\n",
      "epoch 4\n",
      "batch_idx 0\n",
      "dis_train_loss tensor(1.5692, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9880, grad_fn=<AddBackward0>)\n",
      "batch_idx 1\n",
      "dis_train_loss tensor(1.2671, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9533, grad_fn=<AddBackward0>)\n",
      "batch_idx 2\n",
      "dis_train_loss tensor(1.3549, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.4202, grad_fn=<AddBackward0>)\n",
      "batch_idx 3\n",
      "dis_train_loss tensor(1.2714, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2184, grad_fn=<AddBackward0>)\n",
      "batch_idx 4\n",
      "dis_train_loss tensor(1.4245, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1223, grad_fn=<AddBackward0>)\n",
      "batch_idx 5\n",
      "dis_train_loss tensor(1.4953, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1172, grad_fn=<AddBackward0>)\n",
      "batch_idx 6\n",
      "dis_train_loss tensor(1.3551, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.3100, grad_fn=<AddBackward0>)\n",
      "batch_idx 7\n",
      "dis_train_loss tensor(1.3427, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9074, grad_fn=<AddBackward0>)\n",
      "batch_idx 8\n",
      "dis_train_loss tensor(1.4980, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1674, grad_fn=<AddBackward0>)\n",
      "batch_idx 9\n",
      "dis_train_loss tensor(1.3116, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1992, grad_fn=<AddBackward0>)\n",
      "batch_idx 10\n",
      "dis_train_loss tensor(1.2838, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.7738, grad_fn=<AddBackward0>)\n",
      "batch_idx 11\n",
      "dis_train_loss tensor(1.4248, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2544, grad_fn=<AddBackward0>)\n",
      "batch_idx 12\n",
      "dis_train_loss tensor(1.2473, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.3532, grad_fn=<AddBackward0>)\n",
      "batch_idx 13\n",
      "dis_train_loss tensor(1.1790, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0004, grad_fn=<AddBackward0>)\n",
      "batch_idx 14\n",
      "dis_train_loss tensor(1.1824, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.3736, grad_fn=<AddBackward0>)\n",
      "batch_idx 15\n",
      "dis_train_loss tensor(1.3076, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8163, grad_fn=<AddBackward0>)\n",
      "batch_idx 16\n",
      "dis_train_loss tensor(1.4261, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2780, grad_fn=<AddBackward0>)\n",
      "batch_idx 17\n",
      "dis_train_loss tensor(1.4224, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1762, grad_fn=<AddBackward0>)\n",
      "batch_idx 18\n",
      "dis_train_loss tensor(1.2885, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1169, grad_fn=<AddBackward0>)\n",
      "batch_idx 19\n",
      "dis_train_loss tensor(1.2024, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.3105, grad_fn=<AddBackward0>)\n",
      "batch_idx 20\n",
      "dis_train_loss tensor(1.2815, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9370, grad_fn=<AddBackward0>)\n",
      "batch_idx 21\n",
      "dis_train_loss tensor(1.4883, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1176, grad_fn=<AddBackward0>)\n",
      "batch_idx 22\n",
      "dis_train_loss tensor(1.3456, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2359, grad_fn=<AddBackward0>)\n",
      "Train Epoch: 4 Training gen Loss: 1.2359353303909302 dis Loss: 1.345564603805542\n",
      "Validation set: gen_loss: 1.0394010543823242, dis_loss: 1.4858607053756714\n",
      "dis_fooling_rate: 0.22666666559551074, dis_precision: 0.3470220721286276, dis_recall: 0.11806763336062431\n",
      "gen_psnr: 14.907098255360047, gen_ssim: 0.044189585297794286, gen_sam: 0.35603928047677746\n",
      "\n",
      "epoch 5\n",
      "batch_idx 0\n",
      "dis_train_loss tensor(1.5053, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9642, grad_fn=<AddBackward0>)\n",
      "batch_idx 1\n",
      "dis_train_loss tensor(1.3239, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0916, grad_fn=<AddBackward0>)\n",
      "batch_idx 2\n",
      "dis_train_loss tensor(1.1568, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2040, grad_fn=<AddBackward0>)\n",
      "batch_idx 3\n",
      "dis_train_loss tensor(1.1713, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2741, grad_fn=<AddBackward0>)\n",
      "batch_idx 4\n",
      "dis_train_loss tensor(1.0935, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9659, grad_fn=<AddBackward0>)\n",
      "batch_idx 5\n",
      "dis_train_loss tensor(1.4323, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2456, grad_fn=<AddBackward0>)\n",
      "batch_idx 6\n",
      "dis_train_loss tensor(1.4175, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9829, grad_fn=<AddBackward0>)\n",
      "batch_idx 7\n",
      "dis_train_loss tensor(1.2443, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1789, grad_fn=<AddBackward0>)\n",
      "batch_idx 8\n",
      "dis_train_loss tensor(1.7133, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2192, grad_fn=<AddBackward0>)\n",
      "batch_idx 9\n",
      "dis_train_loss tensor(1.5312, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9861, grad_fn=<AddBackward0>)\n",
      "batch_idx 10\n",
      "dis_train_loss tensor(1.3906, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9250, grad_fn=<AddBackward0>)\n",
      "batch_idx 11\n",
      "dis_train_loss tensor(1.3058, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0383, grad_fn=<AddBackward0>)\n",
      "batch_idx 12\n",
      "dis_train_loss tensor(1.2133, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2630, grad_fn=<AddBackward0>)\n",
      "batch_idx 13\n",
      "dis_train_loss tensor(1.1549, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1120, grad_fn=<AddBackward0>)\n",
      "batch_idx 14\n",
      "dis_train_loss tensor(1.1732, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.3220, grad_fn=<AddBackward0>)\n",
      "batch_idx 15\n",
      "dis_train_loss tensor(1.3651, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.7700, grad_fn=<AddBackward0>)\n",
      "batch_idx 16\n",
      "dis_train_loss tensor(1.3910, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1583, grad_fn=<AddBackward0>)\n",
      "batch_idx 17\n",
      "dis_train_loss tensor(1.4167, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0293, grad_fn=<AddBackward0>)\n",
      "batch_idx 18\n",
      "dis_train_loss tensor(1.4043, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9020, grad_fn=<AddBackward0>)\n",
      "batch_idx 19\n",
      "dis_train_loss tensor(1.3622, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0001, grad_fn=<AddBackward0>)\n",
      "batch_idx 20\n",
      "dis_train_loss tensor(1.3731, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9442, grad_fn=<AddBackward0>)\n",
      "batch_idx 21\n",
      "dis_train_loss tensor(1.5775, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8591, grad_fn=<AddBackward0>)\n",
      "batch_idx 22\n",
      "dis_train_loss tensor(1.4075, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9672, grad_fn=<AddBackward0>)\n",
      "Train Epoch: 5 Training gen Loss: 0.9671932458877563 dis Loss: 1.4075111150741577\n",
      "Validation set: gen_loss: 0.8940016627311707, dis_loss: 1.4221010208129883\n",
      "dis_fooling_rate: 0.22260869683130927, dis_precision: 0.6252636857654738, dis_recall: 0.3275362356849339\n",
      "gen_psnr: 15.55102184323388, gen_ssim: 0.060036454147513345, gen_sam: 0.31453839851462323\n",
      "\n",
      "epoch 6\n",
      "batch_idx 0\n",
      "dis_train_loss tensor(1.4542, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9133, grad_fn=<AddBackward0>)\n",
      "batch_idx 1\n",
      "dis_train_loss tensor(1.4048, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9961, grad_fn=<AddBackward0>)\n",
      "batch_idx 2\n",
      "dis_train_loss tensor(1.2729, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0562, grad_fn=<AddBackward0>)\n",
      "batch_idx 3\n",
      "dis_train_loss tensor(1.3965, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8389, grad_fn=<AddBackward0>)\n",
      "batch_idx 4\n",
      "dis_train_loss tensor(1.2145, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1740, grad_fn=<AddBackward0>)\n",
      "batch_idx 5\n",
      "dis_train_loss tensor(1.3446, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0264, grad_fn=<AddBackward0>)\n",
      "batch_idx 6\n",
      "dis_train_loss tensor(1.3734, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8411, grad_fn=<AddBackward0>)\n",
      "batch_idx 7\n",
      "dis_train_loss tensor(1.4137, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9750, grad_fn=<AddBackward0>)\n",
      "batch_idx 8\n",
      "dis_train_loss tensor(1.4800, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0125, grad_fn=<AddBackward0>)\n",
      "batch_idx 9\n",
      "dis_train_loss tensor(1.4353, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8179, grad_fn=<AddBackward0>)\n",
      "batch_idx 10\n",
      "dis_train_loss tensor(1.3559, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0533, grad_fn=<AddBackward0>)\n",
      "batch_idx 11\n",
      "dis_train_loss tensor(1.3097, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0346, grad_fn=<AddBackward0>)\n",
      "batch_idx 12\n",
      "dis_train_loss tensor(1.3811, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8484, grad_fn=<AddBackward0>)\n",
      "batch_idx 13\n",
      "dis_train_loss tensor(1.3106, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9808, grad_fn=<AddBackward0>)\n",
      "batch_idx 14\n",
      "dis_train_loss tensor(1.3139, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8603, grad_fn=<AddBackward0>)\n",
      "batch_idx 15\n",
      "dis_train_loss tensor(1.3303, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9145, grad_fn=<AddBackward0>)\n",
      "batch_idx 16\n",
      "dis_train_loss tensor(1.2867, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0401, grad_fn=<AddBackward0>)\n",
      "batch_idx 17\n",
      "dis_train_loss tensor(1.3099, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0117, grad_fn=<AddBackward0>)\n",
      "batch_idx 18\n",
      "dis_train_loss tensor(1.3045, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1069, grad_fn=<AddBackward0>)\n",
      "batch_idx 19\n",
      "dis_train_loss tensor(1.2214, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0468, grad_fn=<AddBackward0>)\n",
      "batch_idx 20\n",
      "dis_train_loss tensor(1.1781, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1419, grad_fn=<AddBackward0>)\n",
      "batch_idx 21\n",
      "dis_train_loss tensor(1.4303, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0193, grad_fn=<AddBackward0>)\n",
      "batch_idx 22\n",
      "dis_train_loss tensor(1.2658, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1524, grad_fn=<AddBackward0>)\n",
      "Train Epoch: 6 Training gen Loss: 1.1523711681365967 dis Loss: 1.2657665014266968\n",
      "Validation set: gen_loss: 1.1255539655685425, dis_loss: 1.6449233293533325\n",
      "dis_fooling_rate: 0.2970048318738523, dis_precision: 0.23584047154239987, dis_recall: 0.07516908273100853\n",
      "gen_psnr: 15.943351533432168, gen_ssim: 0.1341689890659598, gen_sam: 0.3482268802497698\n",
      "\n",
      "epoch 7\n",
      "batch_idx 0\n",
      "dis_train_loss tensor(1.3917, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.7367, grad_fn=<AddBackward0>)\n",
      "batch_idx 1\n",
      "dis_train_loss tensor(1.4216, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.3069, grad_fn=<AddBackward0>)\n",
      "batch_idx 2\n",
      "dis_train_loss tensor(1.2145, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2217, grad_fn=<AddBackward0>)\n",
      "batch_idx 3\n",
      "dis_train_loss tensor(1.5836, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8335, grad_fn=<AddBackward0>)\n",
      "batch_idx 4\n",
      "dis_train_loss tensor(1.2900, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0125, grad_fn=<AddBackward0>)\n",
      "batch_idx 5\n",
      "dis_train_loss tensor(1.5093, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1509, grad_fn=<AddBackward0>)\n",
      "batch_idx 6\n",
      "dis_train_loss tensor(1.5846, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9507, grad_fn=<AddBackward0>)\n",
      "batch_idx 7\n",
      "dis_train_loss tensor(1.3893, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8566, grad_fn=<AddBackward0>)\n",
      "batch_idx 8\n",
      "dis_train_loss tensor(1.4350, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9254, grad_fn=<AddBackward0>)\n",
      "batch_idx 9\n",
      "dis_train_loss tensor(1.4019, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8711, grad_fn=<AddBackward0>)\n",
      "batch_idx 10\n",
      "dis_train_loss tensor(1.3435, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8828, grad_fn=<AddBackward0>)\n",
      "batch_idx 11\n",
      "dis_train_loss tensor(1.3083, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8868, grad_fn=<AddBackward0>)\n",
      "batch_idx 12\n",
      "dis_train_loss tensor(1.2686, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9804, grad_fn=<AddBackward0>)\n",
      "batch_idx 13\n",
      "dis_train_loss tensor(1.1798, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1349, grad_fn=<AddBackward0>)\n",
      "batch_idx 14\n",
      "dis_train_loss tensor(1.1306, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0663, grad_fn=<AddBackward0>)\n",
      "batch_idx 15\n",
      "dis_train_loss tensor(1.2644, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1308, grad_fn=<AddBackward0>)\n",
      "batch_idx 16\n",
      "dis_train_loss tensor(1.3260, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1656, grad_fn=<AddBackward0>)\n",
      "batch_idx 17\n",
      "dis_train_loss tensor(1.3459, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1384, grad_fn=<AddBackward0>)\n",
      "batch_idx 18\n",
      "dis_train_loss tensor(1.2061, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.3227, grad_fn=<AddBackward0>)\n",
      "batch_idx 19\n",
      "dis_train_loss tensor(1.1210, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.4561, grad_fn=<AddBackward0>)\n",
      "batch_idx 20\n",
      "dis_train_loss tensor(1.2119, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8699, grad_fn=<AddBackward0>)\n",
      "batch_idx 21\n",
      "dis_train_loss tensor(1.5596, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.4903, grad_fn=<AddBackward0>)\n",
      "batch_idx 22\n",
      "dis_train_loss tensor(1.2108, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1968, grad_fn=<AddBackward0>)\n",
      "Train Epoch: 7 Training gen Loss: 1.1967761516571045 dis Loss: 1.210768222808838\n",
      "Validation set: gen_loss: 0.545002281665802, dis_loss: 1.1293967962265015\n",
      "dis_fooling_rate: 0.26318840528635873, dis_precision: 0.7419789122498553, dis_recall: 0.6898550650347834\n",
      "gen_psnr: 15.170119548385768, gen_ssim: 0.04333450224369607, gen_sam: 0.31430604794751044\n",
      "\n",
      "epoch 8\n",
      "batch_idx 0\n",
      "dis_train_loss tensor(1.8267, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8224, grad_fn=<AddBackward0>)\n",
      "batch_idx 1\n",
      "dis_train_loss tensor(1.5449, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0951, grad_fn=<AddBackward0>)\n",
      "batch_idx 2\n",
      "dis_train_loss tensor(1.3585, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0762, grad_fn=<AddBackward0>)\n",
      "batch_idx 3\n",
      "dis_train_loss tensor(1.4395, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9514, grad_fn=<AddBackward0>)\n",
      "batch_idx 4\n",
      "dis_train_loss tensor(1.4090, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9687, grad_fn=<AddBackward0>)\n",
      "batch_idx 5\n",
      "dis_train_loss tensor(1.4070, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8528, grad_fn=<AddBackward0>)\n",
      "batch_idx 6\n",
      "dis_train_loss tensor(1.4731, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9062, grad_fn=<AddBackward0>)\n",
      "batch_idx 7\n",
      "dis_train_loss tensor(1.3830, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0124, grad_fn=<AddBackward0>)\n",
      "batch_idx 8\n",
      "dis_train_loss tensor(1.4583, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9435, grad_fn=<AddBackward0>)\n",
      "batch_idx 9\n",
      "dis_train_loss tensor(1.3342, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9142, grad_fn=<AddBackward0>)\n",
      "batch_idx 10\n",
      "dis_train_loss tensor(1.3501, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8764, grad_fn=<AddBackward0>)\n",
      "batch_idx 11\n",
      "dis_train_loss tensor(1.3459, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9087, grad_fn=<AddBackward0>)\n",
      "batch_idx 12\n",
      "dis_train_loss tensor(1.3142, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9606, grad_fn=<AddBackward0>)\n",
      "batch_idx 13\n",
      "dis_train_loss tensor(1.2413, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0859, grad_fn=<AddBackward0>)\n",
      "batch_idx 14\n",
      "dis_train_loss tensor(1.2239, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0277, grad_fn=<AddBackward0>)\n",
      "batch_idx 15\n",
      "dis_train_loss tensor(1.3571, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9843, grad_fn=<AddBackward0>)\n",
      "batch_idx 16\n",
      "dis_train_loss tensor(1.3061, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9132, grad_fn=<AddBackward0>)\n",
      "batch_idx 17\n",
      "dis_train_loss tensor(1.3277, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0436, grad_fn=<AddBackward0>)\n",
      "batch_idx 18\n",
      "dis_train_loss tensor(1.2725, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0880, grad_fn=<AddBackward0>)\n",
      "batch_idx 19\n",
      "dis_train_loss tensor(1.2670, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1816, grad_fn=<AddBackward0>)\n",
      "batch_idx 20\n",
      "dis_train_loss tensor(1.2838, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9864, grad_fn=<AddBackward0>)\n",
      "batch_idx 21\n",
      "dis_train_loss tensor(1.5314, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1793, grad_fn=<AddBackward0>)\n",
      "batch_idx 22\n",
      "dis_train_loss tensor(1.2014, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2469, grad_fn=<AddBackward0>)\n",
      "Train Epoch: 8 Training gen Loss: 1.2468922138214111 dis Loss: 1.2013559341430664\n",
      "Validation set: gen_loss: 1.24167001247406, dis_loss: 1.6273384094238281\n",
      "dis_fooling_rate: 0.19342995321621065, dis_precision: 0.11695506435859462, dis_recall: 0.017198068049290905\n",
      "gen_psnr: 15.710424589426909, gen_ssim: 0.04878481480235269, gen_sam: 0.3305551059868025\n",
      "\n",
      "epoch 9\n",
      "batch_idx 0\n",
      "dis_train_loss tensor(1.3890, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.7238, grad_fn=<AddBackward0>)\n",
      "batch_idx 1\n",
      "dis_train_loss tensor(1.4861, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1873, grad_fn=<AddBackward0>)\n",
      "batch_idx 2\n",
      "dis_train_loss tensor(1.1041, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.3279, grad_fn=<AddBackward0>)\n",
      "batch_idx 3\n",
      "dis_train_loss tensor(1.5461, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.7160, grad_fn=<AddBackward0>)\n",
      "batch_idx 4\n",
      "dis_train_loss tensor(1.4019, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1578, grad_fn=<AddBackward0>)\n",
      "batch_idx 5\n",
      "dis_train_loss tensor(1.4541, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0017, grad_fn=<AddBackward0>)\n",
      "batch_idx 6\n",
      "dis_train_loss tensor(1.5143, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8856, grad_fn=<AddBackward0>)\n",
      "batch_idx 7\n",
      "dis_train_loss tensor(1.4235, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.7770, grad_fn=<AddBackward0>)\n",
      "batch_idx 8\n",
      "dis_train_loss tensor(1.3914, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9280, grad_fn=<AddBackward0>)\n",
      "batch_idx 9\n",
      "dis_train_loss tensor(1.3520, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9738, grad_fn=<AddBackward0>)\n",
      "batch_idx 10\n",
      "dis_train_loss tensor(1.2925, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9519, grad_fn=<AddBackward0>)\n",
      "batch_idx 11\n",
      "dis_train_loss tensor(1.2532, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9665, grad_fn=<AddBackward0>)\n",
      "batch_idx 12\n",
      "dis_train_loss tensor(1.1989, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1489, grad_fn=<AddBackward0>)\n",
      "batch_idx 13\n",
      "dis_train_loss tensor(1.1328, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9780, grad_fn=<AddBackward0>)\n",
      "batch_idx 14\n",
      "dis_train_loss tensor(1.1596, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.3774, grad_fn=<AddBackward0>)\n",
      "batch_idx 15\n",
      "dis_train_loss tensor(1.3746, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9449, grad_fn=<AddBackward0>)\n",
      "batch_idx 16\n",
      "dis_train_loss tensor(1.3226, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0981, grad_fn=<AddBackward0>)\n",
      "batch_idx 17\n",
      "dis_train_loss tensor(1.3287, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2071, grad_fn=<AddBackward0>)\n",
      "batch_idx 18\n",
      "dis_train_loss tensor(1.3977, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9426, grad_fn=<AddBackward0>)\n",
      "batch_idx 19\n",
      "dis_train_loss tensor(1.2896, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.3778, grad_fn=<AddBackward0>)\n",
      "batch_idx 20\n",
      "dis_train_loss tensor(1.4721, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9433, grad_fn=<AddBackward0>)\n",
      "batch_idx 21\n",
      "dis_train_loss tensor(1.3901, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1546, grad_fn=<AddBackward0>)\n",
      "batch_idx 22\n",
      "dis_train_loss tensor(1.2790, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2979, grad_fn=<AddBackward0>)\n",
      "Train Epoch: 9 Training gen Loss: 1.2979196310043335 dis Loss: 1.2789876461029053\n",
      "Validation set: gen_loss: 1.303969383239746, dis_loss: 1.5575231313705444\n",
      "dis_fooling_rate: 0.14454106176676956, dis_precision: 0.5909402500028196, dis_recall: 0.196135265023812\n",
      "gen_psnr: 15.40276395493944, gen_ssim: 0.10561716978072058, gen_sam: 0.3589976481769396\n",
      "\n",
      "epoch 10\n",
      "batch_idx 0\n",
      "dis_train_loss tensor(1.3825, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8330, grad_fn=<AddBackward0>)\n",
      "batch_idx 1\n",
      "dis_train_loss tensor(1.4104, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.7786, grad_fn=<AddBackward0>)\n",
      "batch_idx 2\n",
      "dis_train_loss tensor(1.3127, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.4454, grad_fn=<AddBackward0>)\n",
      "batch_idx 3\n",
      "dis_train_loss tensor(1.5826, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0314, grad_fn=<AddBackward0>)\n",
      "batch_idx 4\n",
      "dis_train_loss tensor(1.2220, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9962, grad_fn=<AddBackward0>)\n",
      "batch_idx 5\n",
      "dis_train_loss tensor(1.4861, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.7739, grad_fn=<AddBackward0>)\n",
      "batch_idx 6\n",
      "dis_train_loss tensor(1.5427, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9160, grad_fn=<AddBackward0>)\n",
      "batch_idx 7\n",
      "dis_train_loss tensor(1.5028, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8126, grad_fn=<AddBackward0>)\n",
      "batch_idx 8\n",
      "dis_train_loss tensor(1.4416, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8615, grad_fn=<AddBackward0>)\n",
      "batch_idx 9\n",
      "dis_train_loss tensor(1.3429, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8814, grad_fn=<AddBackward0>)\n",
      "batch_idx 10\n",
      "dis_train_loss tensor(1.3169, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9306, grad_fn=<AddBackward0>)\n",
      "batch_idx 11\n",
      "dis_train_loss tensor(1.2589, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9571, grad_fn=<AddBackward0>)\n",
      "batch_idx 12\n",
      "dis_train_loss tensor(1.1934, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0767, grad_fn=<AddBackward0>)\n",
      "batch_idx 13\n",
      "dis_train_loss tensor(1.1520, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1183, grad_fn=<AddBackward0>)\n",
      "batch_idx 14\n",
      "dis_train_loss tensor(1.0842, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2231, grad_fn=<AddBackward0>)\n",
      "batch_idx 15\n",
      "dis_train_loss tensor(1.2299, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.8800, grad_fn=<AddBackward0>)\n",
      "batch_idx 16\n",
      "dis_train_loss tensor(1.3043, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.2174, grad_fn=<AddBackward0>)\n",
      "batch_idx 17\n",
      "dis_train_loss tensor(1.2905, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0988, grad_fn=<AddBackward0>)\n",
      "batch_idx 18\n",
      "dis_train_loss tensor(1.3190, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1235, grad_fn=<AddBackward0>)\n",
      "batch_idx 19\n",
      "dis_train_loss tensor(1.3318, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.3820, grad_fn=<AddBackward0>)\n",
      "batch_idx 20\n",
      "dis_train_loss tensor(1.3372, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.0780, grad_fn=<AddBackward0>)\n",
      "batch_idx 21\n",
      "dis_train_loss tensor(1.4279, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(0.9479, grad_fn=<AddBackward0>)\n",
      "batch_idx 22\n",
      "dis_train_loss tensor(1.3239, grad_fn=<AddBackward0>)\n",
      "gen_train_loss tensor(1.1163, grad_fn=<AddBackward0>)\n",
      "Train Epoch: 10 Training gen Loss: 1.1162748336791992 dis Loss: 1.3238520622253418\n",
      "Validation set: gen_loss: 1.7031033039093018, dis_loss: 1.9462437629699707\n",
      "dis_fooling_rate: 0.1008695658782254, dis_precision: 0.1837963242407726, dis_recall: 0.01526570052880308\n",
      "gen_psnr: 15.394258446481045, gen_ssim: 0.20345295613710926, gen_sam: 0.3273165653581205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_gen_loss, train_dis_loss, val_gen_loss, val_dis_loss = train_gan(gen, dis, opt_gen, opt_dis, epochs) # cl_l2,cl_l1, cl_l2,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "SRGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
